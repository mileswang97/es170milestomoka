{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris shape (150, 4)\n",
      "wine shape (178, 13)\n",
      "bcancer shape (569, 30)\n"
     ]
    }
   ],
   "source": [
    "#preload some datasets\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Want a variety of datasets such that:\n",
    "## Num of features are varied but datapoints are similar (to measure speed vs feature size)\n",
    "## Num of datapoints are varied but features are similar (to measure speed vs dataset size)\n",
    "\n",
    "## DATASET 1: IRIS FROM SKLEARN\n",
    "# imported as dictionary {'data':, 'target':, 'target_names':}\n",
    "iris_dataset = datasets.load_iris()\n",
    "iris_data = np.array(iris_dataset['data'])\n",
    "iris_target = np.array(iris_dataset['target'])\n",
    "\n",
    "## DATASET 2: WINE FROM SKLEARN\n",
    "wine_dataset = datasets.load_wine()\n",
    "wine_data = np.array(wine_dataset['data'])\n",
    "wine_target = np.array(wine_dataset['target'])\n",
    "\n",
    "## DATASET 3: BREAST CANCER FROM SKLEARN\n",
    "bcancer_dataset = datasets.load_breast_cancer()\n",
    "bcancer_data = np.array(bcancer_dataset['data'])\n",
    "bcancer_target = np.array(bcancer_dataset['target'])\n",
    "\n",
    "\n",
    "print(\"iris shape\", iris_data.shape)\n",
    "print(\"wine shape\", wine_data.shape)\n",
    "print(\"bcancer shape\", bcancer_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likely also some ways to generate fake datasets\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def generate_fake_dataset(samples, features, centers, std):\n",
    "    blobs, classes = make_blobs(n_samples=samples, n_features=features, centers=centers, cluster_std=std, random_state=100)\n",
    "    return blobs, classes\n",
    "\n",
    "def plot_dataset_2D(samples, classes):\n",
    "    plt.scatter(samples[:,0], samples[:,1], c=classes)\n",
    "    #plt.xlim(0,1)\n",
    "    #plt.ylim(0,1)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx, testy = generate_fake_dataset(1000, 2, 5, 1)\n",
    "plot_dataset_2D(testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point1, point2):\n",
    "    return np.sqrt(np.sum((point1-point2)*(point1-point2)))\n",
    "\n",
    "def nearest_neighbor_classical(points, centroid_list):\n",
    "    class_array = np.zeros(points.shape[0])\n",
    "    # assign each point to a class\n",
    "    for i in range(points.shape[0]):\n",
    "        min_index = np.argmin([distance(points[i], centroid) for centroid in centroid_list])\n",
    "        class_array[i] = min_index \n",
    "    return class_array\n",
    "\n",
    "def centroid_update(points, class_array, centroid_list):\n",
    "    temp_centroid_list = deepcopy(centroid_list)\n",
    "    for i in range(centroid_list.shape[0]):\n",
    "        # probably need to fix this\n",
    "        #print(points.shape)\n",
    "        #print(temp_centroid_list[i])\n",
    "        class_sum = np.zeros(points.shape[1])\n",
    "        class_num = 0\n",
    "        for j in range(points.shape[0]):\n",
    "            if class_array[j] == i:\n",
    "                class_sum += points[j]\n",
    "                class_num += 1\n",
    "        temp_centroid_list[i] = np.divide(class_sum, class_num)\n",
    "        #print(\"centroid\", temp_centroid_list[i])\n",
    "        #print(class_num)\n",
    "    return temp_centroid_list\n",
    "\n",
    "def kmeans_classical(samples, class_num):\n",
    "    # choose 6 random samples to be the centroids\n",
    "    indices = np.random.randint(samples.shape[0], size=class_num)\n",
    "    centroid_list = np.array([samples[i] for i in indices])\n",
    "    #print(centroid_list)\n",
    "    \n",
    "    #old_class = np.zeros(samples.shape[0])\n",
    "    stop_flag = False\n",
    "    old_centroid_list = centroid_list\n",
    "    start_time = time.time()\n",
    "    counter = 0\n",
    "    #print('old', old_centroid_list)\n",
    "    \n",
    "    # assign classes based on current centroids\n",
    "    while not stop_flag:\n",
    "        counter +=1\n",
    "        #print(counter)\n",
    "        new_class = nearest_neighbor_classical(samples, old_centroid_list)\n",
    "        new_centroid_list = centroid_update(samples, new_class, old_centroid_list)\n",
    "        #print(np.array(old_centroid_list))\n",
    "        #print(np.array(new_centroid_list))\n",
    "        #print(new_class)\n",
    "        if np.sum(np.array(new_centroid_list-old_centroid_list)) == 0:\n",
    "            stop_flag = True\n",
    "            stop_time = time.time()\n",
    "        else:\n",
    "            #print(\"else reached\")\n",
    "            old_centroid_list = new_centroid_list\n",
    "            #old_class = new_class\n",
    "    print(\"time taken: \", stop_time - start_time, \" seconds\")\n",
    "    return samples, new_class, new_centroid_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "a, b, c = kmeans_classical(testx, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure accuary (AUC?)\n",
    "\n",
    "def accuracy(class_list, ground_truth):\n",
    "    diff = class_list - ground_truth\n",
    "    print(diff)\n",
    "    zero_counter = 0\n",
    "    \n",
    "    for entry in diff:\n",
    "        if entry == 0:\n",
    "            zero_counter += 1\n",
    "    \n",
    "    return zero_counter/class_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -2. -2.  0.  3. -2. -2.  1.  1.  3. -2.  3.  0.  3.  0. -2.  3.  3.\n",
      " -2.  3.  3.  1.  0. -2. -2. -2.  3.  0.  1. -2.  0.  1.  1.  1. -2.  3.\n",
      " -2. -2. -2.  1. -2.  1.  3. -2.  3.  1.  1. -2.  0. -2. -2. -2.  0.  3.\n",
      "  1.  3. -2. -2. -2. -2. -2. -2.  3.  1. -2. -2. -2.  1. -2.  1.  0.  3.\n",
      "  0.  3. -2.  3.  3.  0.  0.  3.  1.  3. -2. -2. -2. -2.  3.  3.  3.  1.\n",
      "  1.  0.  1. -2.  1. -2.  1.  1.  1. -2.  0.  3.  1.  1.  1.  0.  3.  3.\n",
      " -2.  1.  3.  3. -2. -2. -2.  1.  1.  1. -2. -2. -2.  0.  0.  0.  1.  3.\n",
      " -2.  0. -2.  0.  0.  1.  3.  3.  3.  0.  3.  0.  0. -2.  3.  1.  0. -2.\n",
      " -2.  1.  3. -2. -2. -2.  3.  1.  1.  0. -2.  3. -2.  1.  3.  1.  0.  3.\n",
      "  1. -2. -2. -2. -2.  3. -2.  0. -2. -2.  1. -2. -2.  0.  0. -2. -2.  0.\n",
      "  3. -2. -2.  0. -2.  1. -2.  0. -2.  1.  3.  1.  1. -2.  0.  1.  3.  0.\n",
      " -2. -2.  1.  1.  0. -2.  3.  1. -2.  0. -2.  0.  3. -2. -2. -2.  1.  3.\n",
      "  1.  3.  3.  1. -2.  1.  3.  3. -2.  1. -2.  0.  0. -2.  0.  3.  3.  0.\n",
      "  3.  0. -2.  1. -2. -2.  1. -2.  1. -2.  3.  1. -2. -2. -2.  0.  1. -2.\n",
      "  0.  0. -2.  3.  1. -2.  1. -2.  1. -2.  0. -2. -2. -2.  3. -2. -2. -2.\n",
      "  3. -2. -2.  3. -2.  0.  0.  0.  1. -2. -2. -2.  3. -2.  3.  0. -2. -2.\n",
      "  1. -2.  3. -2.  1. -2. -2.  1. -2. -2.  0. -2.  0. -2.  0.  3.  0. -2.\n",
      " -2. -2.  1. -2.  3. -2.  0.  0.  0.  3. -2. -2.  3.  3. -2.  1.  0. -2.\n",
      " -2. -2. -2. -2.  3. -2. -2. -2. -2.  1.  0.  3.  3.  3.  3.  0.  0.  0.\n",
      "  0.  0.  1. -2.  0.  3.  3.  0. -2.  0. -2. -2. -2.  0. -2.  3. -2.  3.\n",
      "  3. -2.  3. -2. -2.  1. -2. -2. -2. -2. -2. -2.  0. -2.  0.  1.  1. -2.\n",
      "  0. -2.  1.  1. -2. -2.  0. -2.  0.  0. -2.  3.  1.  3. -2. -2. -2.  1.\n",
      "  0.  3. -2. -2.  0. -2.  1.  3.  1.  0.  3. -2.  1. -2. -2. -2.  0. -2.\n",
      "  3. -2. -2. -2.  0.  1.  3.  3.  3. -2. -2. -2.  1. -2.  3.  1. -2.  0.\n",
      " -2.  0. -2.  1. -2.  3.  0. -2.  3. -2.  0.  3. -2. -2.  0. -2.  3.  3.\n",
      " -2.  3.  1. -2.  3. -2.  0. -2. -2. -2. -2.  3.  3. -2. -2.  1.  0. -2.\n",
      "  1. -2.  1.  0.  0.  1.  3. -2.  3.  0.  1.  0. -2.  1. -2.  0. -2.  1.\n",
      "  3.  3. -2. -2. -2. -2. -2. -2. -2.  3.  1.  0. -2.  3. -2.  1.  3.  0.\n",
      " -2. -2. -2.  0.  1.  1.  1.  3.  1. -2.  3.  0. -2.  1.  0. -2. -2. -2.\n",
      "  1.  0. -2.  3. -2.  3. -2. -2. -2.  3. -2.  3.  3.  3.  0.  3.  1. -2.\n",
      "  0.  3.  1.  3.  3.  0. -2.  3.  1. -2.  1. -2. -2.  0. -2. -2.  3.  3.\n",
      "  3.  0.  3.  3.  3.  1.  0.  1.  3. -2. -2. -2. -2. -2. -2. -2.  3.  0.\n",
      "  1. -2.  3.  1.  3.  1.  0.  1.  0.  3. -2. -2. -2. -2. -2.  0.  3.  1.\n",
      " -2. -2. -2. -2.  3. -2.  0.  0.  0. -2.  1.  3. -2.  0. -2.  0.  3. -2.\n",
      " -2.  3. -2. -2. -2.  1.  3.  0.  3.  0.  0.  1.  1.  0.  3. -2.  1.  0.\n",
      "  3.  0. -2.  0.  3.  1.  1.  1. -2. -2.  3.  1.  0.  0. -2.  1.  0. -2.\n",
      " -2. -2.  1. -2.  3. -2. -2.  1.  3.  0. -2. -2.  3. -2. -2.  3. -2.  3.\n",
      " -2. -2.  1. -2. -2. -2. -2. -2.  0.  0.  3.  0. -2.  1. -2.  3. -2.  0.\n",
      " -2.  0.  1.  0.  1.  3.  0.  0.  3. -2.  0.  0. -2.  3.  0. -2. -2.  0.\n",
      "  3. -2.  1. -2.  1. -2.  3. -2. -2. -2.  1. -2.  0.  1. -2.  3. -2.  3.\n",
      "  3.  0.  1.  3. -2.  1. -2.  3.  3.  3.  1.  3. -2.  1. -2. -2. -2. -2.\n",
      " -2. -2. -2.  1. -2.  0. -2.  0. -2.  3.  0.  1. -2. -2. -2.  1. -2.  1.\n",
      "  3. -2. -2.  1.  1.  1. -2. -2. -2. -2.  0.  3. -2. -2. -2.  1.  0. -2.\n",
      "  3. -2.  3. -2.  3.  1.  3.  3.  3.  0. -2.  1. -2. -2. -2. -2.  1.  1.\n",
      "  3.  1.  1.  1. -2. -2.  3. -2. -2.  0.  3. -2.  0.  1. -2.  0. -2.  1.\n",
      "  3. -2.  0. -2.  1.  3. -2.  1.  1. -2. -2.  0.  0. -2.  1. -2.  0.  0.\n",
      " -2.  0.  3.  0.  0.  0. -2.  0.  3.  0.  1.  1.  0.  3. -2.  0. -2. -2.\n",
      "  0.  0.  1.  1.  1.  0.  0.  3.  3. -2. -2.  3. -2. -2. -2. -2.  3.  3.\n",
      "  1.  3.  1. -2.  1. -2.  0.  3.  1.  3. -2. -2. -2. -2.  1.  3.  1.  0.\n",
      "  1. -2.  0.  1.  3.  1.  1.  0. -2.  1. -2.  1.  3. -2.  0.  1.  0.  1.\n",
      "  3.  3.  1. -2.  3.  1.  1.  3. -2. -2.  1. -2. -2. -2.  1.  0. -2. -2.\n",
      " -2.  0.  1.  1. -2.  1.  0. -2.  0. -2.  0.  0.  0.  3. -2.  0.  1. -2.\n",
      "  3.  3.  0.  0.  0.  1. -2.  1.  0. -2. -2.  0.  3.  0.  3.  1. -2.  0.\n",
      " -2.  1. -2.  1.  0.  1.  1.  0.  0.  3.  0.  3. -2.  0.  1. -2. -2. -2.\n",
      " -2.  1.  3. -2.  0.  0.  3.  1.  0.  1.  0. -2. -2.  1.  0. -2. -2.  1.\n",
      " -2.  3. -2.  1.  0. -2. -2.  1.  3.  0.]\n",
      "0.198\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(b,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical k means\n",
    "\n",
    "def cluster_assignment():\n",
    "    \n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def kmeans_classical():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "def K_Means(features, target, search_grid):\n",
    "    kmeans = KMeans()\n",
    "    kmeans_random = RandomizedSearchCV(estimator = kmeans, param_distributions = search_grid)\n",
    "    time_start = time.time()\n",
    "    \n",
    "    search = kmeans_random.fit(features, target)\n",
    "    k_final = search.best_estimator_\n",
    "    print('time taken: ', time.time() - time_start)\n",
    "    print(k_final)\n",
    "    print(search.best_score_)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = [2,3,4,5,6,7,8,9,10] \n",
    "n_init = [2,5,10,20]\n",
    "max_iter = [300,600,1000]\n",
    "tol = [1e-4]\n",
    "precompute_distances = ['auto', True, False]\n",
    "njobs = [-1]\n",
    "algorithm = ['auto', 'full', 'elkan']\n",
    "\n",
    "random_grid = {\n",
    "    'n_clusters': n_clusters,\n",
    "    'n_init' : n_init,\n",
    "    'max_iter' : max_iter,\n",
    "    'tol' : tol,\n",
    "    'precompute_distances' : precompute_distances,\n",
    "    'n_jobs' : njobs,\n",
    "    'algorithm' : algorithm\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  0.4293074607849121\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=600,\n",
      "       n_clusters=10, n_init=5, n_jobs=-1, precompute_distances='auto',\n",
      "       random_state=None, tol=0.0001, verbose=0)\n",
      "-136.9407598765433\n"
     ]
    }
   ],
   "source": [
    "K_Means(iris_data, iris_target, random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  0.3847661018371582\n",
      "KMeans(algorithm='full', copy_x=True, init='k-means++', max_iter=600,\n",
      "       n_clusters=10, n_init=2, n_jobs=-1, precompute_distances='auto',\n",
      "       random_state=None, tol=0.0001, verbose=0)\n",
      "-1430808.932699262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "K_Means(wine_data, wine_target, random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  0.630089521408081\n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
      "       n_clusters=10, n_init=2, n_jobs=-1, precompute_distances=True,\n",
      "       random_state=None, tol=0.0001, verbose=0)\n",
      "-4243492.788923874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miles\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "K_Means(bcancer_data, bcancer_target, random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
